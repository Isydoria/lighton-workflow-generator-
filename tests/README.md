# Tests - LightOn Workflow Builder

Suite de tests complÃ¨te pour les endpoints Paradigm API et l'API backend.

## ğŸ“‹ Vue d'ensemble

Cette suite de tests couvre :
- âœ… **11 endpoints Paradigm API** (document-search, document-analysis, files, chunks, etc.)
- âœ… **Endpoints backend** (workflows, exÃ©cution, files, PDF export)
- âœ… **Tests d'intÃ©gration** end-to-end
- âœ… **Tests de sÃ©curitÃ©** du sandbox
- âœ… **Tests de performance** et concurrence

## ğŸš€ DÃ©marrage Rapide

```bash
# Installer les dÃ©pendances
make install

# VÃ©rifier les variables d'environnement
make verify-env

# Lancer tous les tests
make test

# Tests rapides uniquement
make test-quick
```

## ğŸ“¦ Structure

```
tests/
â”œâ”€â”€ Makefile                    # Commandes de test
â”œâ”€â”€ conftest.py                 # Configuration pytest
â”œâ”€â”€ test_paradigm_api.py        # Tests endpoints Paradigm (11 endpoints)
â”œâ”€â”€ test_workflow_api.py        # Tests workflows (crÃ©ation, exÃ©cution)
â”œâ”€â”€ test_files_api.py           # Tests fichiers (upload, query)
â”œâ”€â”€ test_integration.py         # Tests end-to-end
â”œâ”€â”€ test_security.py            # Tests sÃ©curitÃ© sandbox
â””â”€â”€ README.md                   # Ce fichier
```

## ğŸ”§ Configuration

### Variables d'Environnement Requises

CrÃ©er un fichier `.env` Ã  la racine du projet :

```bash
# ClÃ©s API
LIGHTON_API_KEY=your_lighton_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# URLs (optionnel)
API_BASE_URL=http://localhost:8000
PARADIGM_BASE_URL=https://paradigm.lighton.ai
```

### Installation

```bash
# Installer pytest et dÃ©pendances
make install

# VÃ©rifier la configuration
make verify-env

# VÃ©rifier que l'API backend rÃ©pond
make check-api
```

## ğŸ§ª Commandes de Test

### Tests GÃ©nÃ©raux

```bash
make test              # Tous les tests avec couverture
make test-quick        # Tests rapides uniquement (sans slow)
make test-smoke        # Test rapide de santÃ© de l'API
make test-verbose      # Tests en mode trÃ¨s verbeux
make test-failed       # Relancer uniquement les tests Ã©chouÃ©s
```

### Tests par CatÃ©gorie

```bash
make test-paradigm     # Tests endpoints Paradigm API
make test-workflow     # Tests crÃ©ation/exÃ©cution workflows
make test-files        # Tests upload/gestion fichiers
make test-integration  # Tests scÃ©narios end-to-end
make test-security     # Tests sÃ©curitÃ© sandbox
```

### Couverture et Rapports

```bash
make test-coverage     # GÃ©nÃ©rer rapport de couverture HTML
make report            # Afficher rÃ©sumÃ© du dernier test
```

### Gestion de l'API

```bash
make start-api         # DÃ©marrer l'API backend
make stop-api          # ArrÃªter l'API backend
make check-api         # VÃ©rifier que l'API rÃ©pond
make logs-api          # Afficher les logs de l'API
```

### Workflow Complet

```bash
make full-test         # Cycle complet: dÃ©marrer API â†’ tester â†’ arrÃªter
make ci-test           # Tests pour CI/CD (sans dÃ©marrage API)
```

### Utilitaires

```bash
make clean             # Nettoyer fichiers de test
make help              # Afficher l'aide
```

## ğŸ“Š Tests Paradigm API

### Endpoints TestÃ©s (11/11)

| Endpoint | Tests | Status |
|----------|-------|--------|
| `POST /api/v2/chat/document-search` | 3 tests | âœ… |
| `POST /api/v2/chat/document-analysis` | 2 tests | âœ… |
| `POST /api/v2/chat/completions` | 2 tests | âœ… |
| `POST /api/v2/files` | 5 tests | âœ… |
| `GET /api/v2/files/{id}` | 3 tests | âœ… |
| `POST /api/v2/files/{id}/ask` | 4 tests | âœ… |
| `GET /api/v2/files/{id}/chunks` | 1 test | âœ… |
| `POST /api/v2/filter/chunks` | 1 test | âœ… |
| `POST /api/v2/query` | 1 test | âœ… |
| `POST /api/v2/chat/image-analysis` | 1 test | âœ… |
| Gestion d'erreurs | 3 tests | âœ… |

**Total: 26 tests pour Paradigm API**

### Exemples de Tests Paradigm

```bash
# Test recherche sÃ©mantique
pytest tests/test_paradigm_api.py::TestParadigmDocumentSearch::test_document_search_basic -v

# Test upload de fichier
pytest tests/test_paradigm_api.py::TestParadigmFiles::test_file_upload -v

# Test chat completion
pytest tests/test_paradigm_api.py::TestParadigmChatCompletions::test_chat_completion_basic -v
```

## ğŸ“Š Tests Backend API

### Endpoints TestÃ©s

| CatÃ©gorie | Endpoints | Tests |
|-----------|-----------|-------|
| Workflows | 7 endpoints | 15 tests |
| Files | 4 endpoints | 18 tests |
| ExÃ©cution | 3 endpoints | 8 tests |
| Export PDF | 1 endpoint | 2 tests |

**Total: 43 tests backend**

### Exemples de Tests Backend

```bash
# Test crÃ©ation workflow
pytest tests/test_workflow_api.py::TestWorkflowCreation::test_create_simple_workflow -v

# Test exÃ©cution workflow
pytest tests/test_workflow_api.py::TestWorkflowExecution::test_execute_simple_workflow -v

# Test upload fichier
pytest tests/test_files_api.py::TestFileUpload::test_upload_text_file -v
```

## ğŸ”— Tests d'IntÃ©gration

Tests de scÃ©narios utilisateur complets :

```bash
# Cycle complet: Upload â†’ Workflow â†’ ExÃ©cution â†’ PDF
pytest tests/test_integration.py::TestCompleteUserJourney -v

# Workflow avec recherche de documents
pytest tests/test_integration.py::TestFileToWorkflowIntegration -v

# ExÃ©cution parallÃ¨le de workflows
pytest tests/test_integration.py::TestMultipleWorkflowsParallel -v
```

**Total: 12 tests d'intÃ©gration**

## ğŸ”’ Tests de SÃ©curitÃ©

Tests des vulnÃ©rabilitÃ©s identifiÃ©es dans l'analyse :

```bash
# Tests sandbox (accÃ¨s fichiers, OS, imports)
pytest tests/test_security.py::TestSandboxSecurity -v

# Tests validation d'entrÃ©es (XSS, SQL injection)
pytest tests/test_security.py::TestInputValidation -v

# Tests exposition clÃ©s API
pytest tests/test_security.py::TestAPIKeyExposure -v
```

**Total: 16 tests de sÃ©curitÃ©**

### VulnÃ©rabilitÃ©s TestÃ©es

- âš ï¸ AccÃ¨s systÃ¨me de fichiers
- âš ï¸ Injection de commandes OS
- âš ï¸ Import de modules dangereux
- âš ï¸ Utilisation de eval/exec
- âš ï¸ Ã‰puisement mÃ©moire
- âš ï¸ Boucles infinies
- âš ï¸ Exposition de clÃ©s API
- âš ï¸ Rate limiting
- âš ï¸ CORS permissif

## ğŸ¯ Markers Pytest

Utiliser les markers pour filtrer les tests :

```bash
# Tests par catÃ©gorie
pytest -m paradigm      # Tests Paradigm API
pytest -m workflow      # Tests Workflow API
pytest -m files         # Tests Files API
pytest -m integration   # Tests d'intÃ©gration
pytest -m security      # Tests de sÃ©curitÃ©

# Exclure tests lents
pytest -m "not slow"

# Combiner markers
pytest -m "paradigm and not slow"
```

## ğŸ“ˆ Couverture de Code

```bash
# GÃ©nÃ©rer rapport de couverture
make test-coverage

# Ouvrir le rapport HTML
open htmlcov/index.html  # macOS
xdg-open htmlcov/index.html  # Linux
```

Objectif : **> 80% de couverture**

## âš¡ Performance

### Tests de Performance

```bash
# RequÃªtes concurrentes
pytest tests/test_paradigm_api.py::TestParadigmPerformance -v

# Workflows parallÃ¨les
pytest tests/test_workflow_api.py::TestWorkflowConcurrency -v
```

### Benchmark

```bash
# Lancer les benchmarks
make benchmark
```

## ğŸ› Debugging

### Tests Verbeux

```bash
# Afficher toutes les sorties
pytest -vv --tb=long

# Afficher print statements
pytest -s

# ArrÃªter au premier Ã©chec
pytest -x
```

### Tests SpÃ©cifiques

```bash
# Lancer un test spÃ©cifique
pytest tests/test_paradigm_api.py::TestParadigmDocumentSearch::test_document_search_basic -v

# Lancer une classe de tests
pytest tests/test_workflow_api.py::TestWorkflowCreation -v

# Lancer un fichier
pytest tests/test_files_api.py -v
```

### Mode Watch

```bash
# Relancer automatiquement lors de changements
make test-watch
```

## ğŸ”„ CI/CD

### GitHub Actions / GitLab CI

```yaml
# Exemple configuration CI
test:
  script:
    - cd tests
    - make install
    - make verify-env
    - make ci-test
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
```

### Variables CI/CD Requises

```
LIGHTON_API_KEY
ANTHROPIC_API_KEY
```

## ğŸ“ Ã‰crire de Nouveaux Tests

### Template de Test

```python
import pytest
import httpx

@pytest.mark.asyncio
@pytest.mark.paradigm  # ou workflow, files, etc.
async def test_my_feature(api_headers):
    """Description du test"""
    async with httpx.AsyncClient(timeout=60.0) as client:
        # Arrange
        payload = {"key": "value"}

        # Act
        response = await client.post(
            f"{API_BASE_URL}/endpoint",
            headers=api_headers,
            json=payload
        )

        # Assert
        assert response.status_code == 200
        data = response.json()
        assert "expected_field" in data
```

### Bonnes Pratiques

1. **Utiliser les fixtures** pour le setup/cleanup
2. **Markers appropriÃ©s** (paradigm, workflow, files, security, slow)
3. **Tests atomiques** : un test = une fonctionnalitÃ©
4. **Noms descriptifs** : `test_what_when_expected`
5. **Assertions claires** avec messages d'erreur
6. **Cleanup** : supprimer les ressources crÃ©Ã©es
7. **Timeouts** : toujours dÃ©finir un timeout

## ğŸ“Š Statistiques

### RÃ©sumÃ©

- **Total de tests** : ~97 tests
- **Couverture** : 11/11 endpoints Paradigm API
- **Temps d'exÃ©cution** : ~5-10 minutes (tous les tests)
- **Tests rapides** : ~2 minutes

### Distribution

```
test_paradigm_api.py    : 26 tests (Paradigm API)
test_workflow_api.py    : 15 tests (Workflows)
test_files_api.py       : 18 tests (Files)
test_integration.py     : 12 tests (End-to-end)
test_security.py        : 16 tests (SÃ©curitÃ©)
---
Total                   : 97 tests
```

## ğŸ” Troubleshooting

### Erreur: LIGHTON_API_KEY non dÃ©finie

```bash
# DÃ©finir dans .env ou exporter
export LIGHTON_API_KEY=your_key_here
```

### Erreur: API ne rÃ©pond pas

```bash
# DÃ©marrer l'API backend
make start-api

# VÃ©rifier les logs
make logs-api
```

### Tests qui timeout

```bash
# Augmenter les timeouts dans les tests
# Ou utiliser tests rapides
make test-quick
```

### Ã‰checs de tests de sÃ©curitÃ©

Les tests de sÃ©curitÃ© **documentent les vulnÃ©rabilitÃ©s** identifiÃ©es dans l'analyse. Certains Ã©checs sont attendus et indiquent des amÃ©liorations nÃ©cessaires.

## ğŸ“š RÃ©fÃ©rences

- [Pytest Documentation](https://docs.pytest.org/)
- [HTTPX Documentation](https://www.python-httpx.org/)
- [Paradigm API Documentation](https://paradigm.lighton.ai/docs)
- [Analyse de ConformitÃ©](../docs/analyse-conformite-architecture.md)

## ğŸ¤ Contribution

Pour ajouter de nouveaux tests :

1. Suivre le template ci-dessus
2. Ajouter les markers appropriÃ©s
3. Mettre Ã  jour ce README
4. Lancer `make test` avant de commiter

## ğŸ“ Support

Pour toute question sur les tests, consulter :
- [Documentation principale](../README.md)
- [Analyse de conformitÃ©](../docs/analyse-conformite-architecture.md)
- Issues GitHub du projet
