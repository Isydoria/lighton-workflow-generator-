"""
FastAPI Backend for Standalone Workflow Runner
===============================================

This is a simple backend server that:
1. Serves the frontend files
2. Receives file uploads and user input
3. Executes the workflow
4. Returns results

Generated by LightOn Workflow Builder
"""

import os
import time
import asyncio
import logging
from typing import List, Optional
from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel

# Import the generated workflow
from workflow import execute_workflow, paradigm_client

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Create FastAPI app
app = FastAPI(
    title="{{WORKFLOW_NAME}}",
    description="Standalone workflow runner generated by LightOn Workflow Builder",
    version="1.0.0"
)

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Models
class ExecutionResponse(BaseModel):
    status: str
    result: str
    execution_time: float
    execution_id: str


@app.get("/")
async def serve_frontend():
    """Serve the frontend HTML"""
    return FileResponse("../frontend/index.html")


@app.get("/config.json")
async def serve_config():
    """Serve the workflow configuration"""
    return FileResponse("../frontend/config.json")


@app.post("/execute", response_model=ExecutionResponse)
async def execute(
    user_input: str = Form(""),
    files: List[UploadFile] = File(default=[])
):
    """
    Execute the workflow with uploaded files and user input.

    Args:
        user_input: Text input from the user
        files: List of uploaded files

    Returns:
        ExecutionResponse with results
    """
    execution_id = f"exec_{int(time.time() * 1000)}"
    start_time = time.time()

    logger.info(f"[{execution_id}] Starting workflow execution")
    logger.info(f"[{execution_id}] User input: {user_input[:100]}...")
    logger.info(f"[{execution_id}] Files uploaded: {len(files)}")

    try:
        # Upload files to Paradigm if any
        file_ids = []
        if files and files[0].filename:  # Check if files were actually uploaded
            logger.info(f"[{execution_id}] Uploading {len(files)} files to Paradigm...")

            for file in files:
                logger.info(f"[{execution_id}] Uploading: {file.filename}")

                # Read file content
                file_content = await file.read()

                # Upload to Paradigm
                upload_result = await paradigm_client.upload_file(
                    file_content=file_content,
                    filename=file.filename,
                    collection_type="private"
                )

                file_id = upload_result.get("id") or upload_result.get("file_id")
                file_ids.append(file_id)
                logger.info(f"[{execution_id}] File uploaded: {file.filename} -> ID: {file_id}")

            # Wait for files to be processed and indexed by Paradigm
            logger.info(f"[{execution_id}] Waiting for files to be indexed...")
            await asyncio.sleep(10)  # Wait 10 seconds for indexing

        # Set global variable for workflow to access
        import builtins
        if file_ids:
            builtins.attached_file_ids = file_ids

        # Execute workflow
        logger.info(f"[{execution_id}] Executing workflow...")
        result = await execute_workflow(user_input)

        execution_time = round(time.time() - start_time, 2)
        logger.info(f"[{execution_id}] Workflow completed in {execution_time}s")

        return ExecutionResponse(
            status="completed",
            result=result,
            execution_time=execution_time,
            execution_id=execution_id
        )

    except Exception as e:
        execution_time = round(time.time() - start_time, 2)
        error_message = f"Workflow execution failed: {str(e)}"
        logger.error(f"[{execution_id}] {error_message}")

        return ExecutionResponse(
            status="failed",
            result=error_message,
            execution_time=execution_time,
            execution_id=execution_id
        )


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "workflow": "{{WORKFLOW_NAME}}",
        "version": "1.0.0"
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )
