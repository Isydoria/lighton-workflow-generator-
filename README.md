# LightOn Workflow Builder

Application de gÃ©nÃ©ration et d'exÃ©cution de workflows automatisÃ©s utilisant l'API Anthropic Claude et l'API LightOn Paradigm.

## ğŸš€ DÃ©marrage Rapide

### DÃ©veloppement quotidien
Double-cliquez sur **`dev.bat`**
- DÃ©marre le serveur en mode dÃ©veloppement
- Frontend : http://localhost:3000
- Backend API : http://localhost:8000/docs

### Test avant dÃ©ploiement
Double-cliquez sur **`test-docker.bat`**
- Teste l'application dans Docker (environnement de production)
- VÃ©rifiez que tout fonctionne avant de dÃ©ployer

## ğŸ“‹ PrÃ©requis

1. **Python 3.11+** installÃ©
2. **Docker Desktop** (pour les tests Docker uniquement)
3. **Fichier .env** avec vos clÃ©s API :
   ```env
   ANTHROPIC_API_KEY=votre_clÃ©_anthropic
   LIGHTON_API_KEY=votre_clÃ©_lighton
   ```

## ğŸ› ï¸ Workflow de DÃ©veloppement

```
1. DÃ©velopper        â†’ dev.bat
2. Tester            â†’ http://localhost:3000
3. Test Docker       â†’ test-docker.bat (avant commit)
4. Commit & Push     â†’ git commit && git push
5. DÃ©ploiement       â†’ Automatique sur Vercel
```

## âœ¨ FonctionnalitÃ©s

- **Natural Language to Code**: DÃ©crivez vos workflows en langage naturel
- **LightOn Paradigm Integration**: Recherche et analyse de documents
- **Safe Code Execution**: Environnement d'exÃ©cution sÃ©curisÃ© avec timeout
- **RESTful API**: API FastAPI propre et bien documentÃ©e
- **Async Support**: OpÃ©rations asynchrones pour de meilleures performances

## ğŸ”§ Installation Manuelle (si besoin)

1. **Installer les dÃ©pendances**
   ```bash
   pip install -r requirements.txt
   ```

2. **Configurer les clÃ©s API**

   CrÃ©ez un fichier `.env` Ã  la racine :
   ```bash
   ANTHROPIC_API_KEY=votre_clÃ©_anthropic
   LIGHTON_API_KEY=votre_clÃ©_lighton

   # Redis (optionnel - pour persistance serverless)
   # Vercel KV (automatique si liÃ© depuis Vercel)
   KV_REST_API_URL=https://your-redis.upstash.io
   KV_REST_API_TOKEN=your_token_here

   # OU Upstash direct (configuration manuelle)
   UPSTASH_REDIS_REST_URL=https://your-redis.upstash.io
   UPSTASH_REDIS_REST_TOKEN=your_token_here
   ```

3. **DÃ©marrer le serveur**
   ```bash
   # Utilisez plutÃ´t dev.bat (recommandÃ©)
   # Ou manuellement :
   python -m uvicorn api.index:app --port 8000
   ```

## API Usage

### 1. Create a Workflow

```bash
curl -X POST "http://localhost:8000/workflows" \
  -H "Content-Type: application/json" \
  -d '{
    "description": "For each sentence in user input, search using paradigm_search, then format as Question: [sentence] Answer: [result]",
    "name": "Sentence Processing Workflow"
  }'
```

### 2. Execute a Workflow

```bash
curl -X POST "http://localhost:8000/workflows/{workflow_id}/execute" \
  -H "Content-Type: application/json" \
  -d '{
    "user_input": "What is machine learning? How does AI work?"
  }'
```

### 3. Get Workflow Details

```bash
curl -X GET "http://localhost:8000/workflows/{workflow_id}"
```

## Example Workflow

The system is designed to handle workflows like the example provided:

**Description**: "User inputs a long prompt with multiple sentences. For each sentence, perform a search using the Paradigm Docsearch tool. Return results formatted as 'Question: [sentence]' followed by 'Answer: [result]'."

**Sample Input**: "What is machine learning? How does artificial intelligence work? What are the benefits of cloud computing?"

**Expected Output**:
```
Question: What is machine learning?
Answer: [Search result about machine learning]

Question: How does artificial intelligence work?
Answer: [Search result about AI]

Question: What are the benefits of cloud computing?
Answer: [Search result about cloud computing benefits]
```

## Available Tools in Workflows

Generated workflows have access to these tools:

- `paradigm_search(query: str) -> str`: Search documents using LightOn Paradigm
- `chat_completion(prompt: str) -> str`: Get AI responses using Anthropic API

## Testing

Run the example test to verify everything works:

```bash
python test_example.py
```

## ğŸ“ Structure du Projet

```
â”œâ”€â”€ api/                    # Backend FastAPI
â”‚   â”œâ”€â”€ config.py          # Configuration (charge .env)
â”‚   â”œâ”€â”€ main.py            # Application FastAPI
â”‚   â”œâ”€â”€ models.py          # ModÃ¨les de donnÃ©es
â”‚   â”œâ”€â”€ api_clients.py     # Clients API (Paradigm)
â”‚   â””â”€â”€ workflow/          # GÃ©nÃ©rateur et exÃ©cuteur de workflows
â”œâ”€â”€ index.html             # Frontend
â”œâ”€â”€ .env                   # Variables d'environnement (NE PAS commiter!)
â”œâ”€â”€ docker-compose.yml     # Configuration Docker
â”œâ”€â”€ Dockerfile             # Image Docker
â”œâ”€â”€ dev.bat               # Script de dÃ©veloppement
â””â”€â”€ test-docker.bat       # Script de test Docker
```

## ğŸ³ DÃ©ploiement

### Docker (test local)
```bash
# Build et dÃ©marrage
docker-compose up --build

# ArrÃªt
docker-compose down
```

### Vercel (production)
1. Connectez votre repo GitHub/GitLab Ã  Vercel
2. Ajoutez les variables d'environnement dans Vercel :
   - `ANTHROPIC_API_KEY`
   - `LIGHTON_API_KEY`
3. Liez Vercel KV (Storage) :
   - Les variables `KV_REST_API_URL` et `KV_REST_API_TOKEN` sont crÃ©Ã©es automatiquement
   - Le code dÃ©tecte et utilise ces variables automatiquement
4. DÃ©ployez : `git push` (automatique)

**Note** : Le code supporte automatiquement les deux conventions :
- Variables Vercel KV (crÃ©Ã©es automatiquement lors du linking)
- Variables Upstash directes (configuration manuelle)

## ğŸ“š Documentation

- **API Backend** : http://localhost:8000/docs (quand le serveur tourne)
- **Docker** : Voir [DOCKER_README.md](DOCKER_README.md)
- **API Paradigm** : https://paradigm.lighton.ai/docs

## ğŸ”’ SÃ©curitÃ©

- **Sandboxed Execution**: Le code s'exÃ©cute dans un environnement restreint
- **Timeout Protection**: Les exÃ©cutions sont limitÃ©es dans le temps
- **Input Validation**: Toutes les entrÃ©es sont validÃ©es
- **Error Handling**: Gestion complÃ¨te des erreurs et logging

## ğŸ› DÃ©pannage

**ProblÃ¨me : "Port already in use"**
- Les scripts `dev.bat` et `test-docker.bat` tuent automatiquement les anciens serveurs
- Si problÃ¨me persiste : `powershell "Get-Process python | Stop-Process -Force"`

**ProblÃ¨me : "API key not configured"**
- VÃ©rifiez que le fichier `.env` existe Ã  la racine du projet
- VÃ©rifiez que les clÃ©s API sont correctes
- RedÃ©marrez avec `dev.bat`

## ğŸ“ Technologies

- **Backend** : FastAPI, Python 3.11+
- **Frontend** : HTML/CSS/JavaScript vanilla
- **AI** : Anthropic Claude API
- **Document Processing** : LightOn Paradigm API
- **DÃ©ploiement** : Vercel (prod), Docker (test)